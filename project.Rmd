---
title: "predmachlearn-031"
author: "Paolo Nicorelli"
date: "August 22, 2015"
output: html_document
---


# Executive Summary

Six young health people were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

[more info here](http://groupware.les.inf.puc-rio.br/har)

The aim of this report is to build up a model for Exercise Class machine learning prediction.

# R Library 

```{r}
library('caret')
library('corrplot')
```

# Data Fetching

There are 2 files to download:
- pml-training.csv: **~11.6MB** the data for train the algorithm
- pml-testing.csv: **~14.8KB** the data to predict (without classification)

```{r}
trainingFile <- 'pml-training.csv'
testingFile <- 'pml-testing.csv'

if(!file.exists(trainingFile)){
  download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', destfile=trainingFile, method='curl')
}
if(!file.exists(testingFile)){
  download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv', destfile=testingFile, method='curl')
}
```

# Load and Clean data

The first 8 columns are headers columns refered to the user, the timedate and we can skip it. We skip also the column with all *na*.

```{r}
training <- read.csv('pml-training.csv', na.strings=c("NA","#DIV/0!", ""), header=TRUE)
testing <- read.csv('pml-testing.csv', na.strings=c("NA","#DIV/0!", ""), header=TRUE)

## Remove the headers columns
trainingData <- training[,-c(1:7)]
testingData <- testing[,-c(1:7)]

# Delete columns with all missing values
trainingData<-trainingData[,colSums(is.na(trainingData)) == 0]
testingData <-testingData[,colSums(is.na(testingData)) == 0]
```

In order to evaluate our model we use a partition of the *training* data for testing purpose (remember we have not the result in the *testing* file).

```{r}
inTrain <- createDataPartition(y = trainingData$classe, p = 0.7, list = FALSE)
trainingDataPart <- trainingData[inTrain, ]
trainingDataCrossV <- trainingData[-inTrain, ]
```

# Build a model 

The predictive model is build up with the Random Forest algorithm.

```{r}
modelRandomForest <- train( classe~., data=trainingDataPart, method="rf")
```

# Cross Validation

We now use the 30% of the train data to evaluate our model

```{r}
predictCrossV <- predict(modelRandomForest, trainingDataCrossV)
cm <- confusionMatrix(trainingDataCrossV$classe, predictCrossV)
cm$table
```

Our Random Forest algorithm has an accouracy of `r cm$overall[[1]]`

# Prediction

Predict the result of the *testing* set is now quite simple:

```{r}
rfPred <- predict(modelRandomForest, newdata = testingData)
```

and the result is **`r rfPred`**